from pathlib import Path
import uuid
import re
from langchain_core.documents import Document
from langchain_classic.retrievers import ContextualCompressionRetriever
from langchain_core.retrievers import BaseRetriever
from retrieval import hybrid_summary_search
from reranker import summary_compressor
from llm import llm, fallback_llm
from semantic_cache import semantic_cache
from stats import stats
from langdetect import detect
from logger_setup import setup_logger
from support_handoff import handoff
from langdetect import detect
from conversation_manager import conversation_state
from chat_history_manager import chat_history
from feedback_manager import feedback_manager
from dwh_product_search import dwh_search

logger = setup_logger()

BUSINESS_ENTITIES = {
    "birbonus": [
        "–±–∏—Ä–±–æ–Ω—É—Å", "–±–∏—Ä –±–æ–Ω—É—Å", "birbonus", "bir bomus",
        "bir-bonus", "birbonuz",
    ],
    "birmarket": [
        "–±–∏—Ä–º–∞—Ä–∫–µ—Ç", "–±–∏—Ä –º–∞—Ä–∫–µ—Ç", "birmarket", "bir market",
        "birmarkat", "bir-market",
    ],
}


def normalize_query(query: str) -> str:
    """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–ø—Ä–æ—Å–∞ —Å –∑–∞–º–µ–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –Ω–∞–∑–≤–∞–Ω–∏–π"""
    q = query.lower()
    for canonical, variants in BUSINESS_ENTITIES.items():
        for v in variants:
            q = re.sub(rf"\b{re.escape(v)}\b", canonical, q)
    return q


def contextualize_query(query: str, user_id: str | None) -> str:
    """
    –ü–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä—É–µ—Ç –∑–∞–ø—Ä–æ—Å –≤ —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω—ã–π, –µ—Å–ª–∏ –æ–Ω —Å—Å—ã–ª–∞–µ—Ç—Å—è –Ω–∞ –∏—Å—Ç–æ—Ä–∏—é.
    """
    if not user_id:
        return query

    try:
        history = chat_history.get_history(user_id)
        previous_queries = [
            msg.content for msg in history
            if msg.role == "user"
        ][:10]

        if not previous_queries:
            return query

        history_text = "\n".join([f"User: {q}" for q in previous_queries])

        system_prompt = (
            "You are a helpful assistant that reformulates the latest user question "
            "into a standalone question that can be fully understood without the chat history. "
            "You work in customer support for Birmarket (online marketplace in Azerbaijan). "
            "Users communicate in Russian, Azerbaijani or English.\n\n"
            "INSTRUCTIONS:\n"
            "- Reformulate ONLY if the question refers to previous context "
            "(e.g. '—ç—Ç–æ', '–æ–Ω', '—Ç–∞ —Ç–æ–≤–∞—Ä', 'bu', 'o', 'h…ômin', '—Å–∫–æ–ª—å–∫–æ —Å—Ç–æ–∏—Ç?', etc.).\n"
            "- Keep the SAME language as the latest question.\n"
            "- DO NOT answer the question ‚Äî only return the standalone version.\n"
            "- If the question is already independent ‚Äî return it AS IS.\n"
            "- Do not add any explanations."
        )

        user_prompt = f"""Chat history (user questions only):
{history_text}

Latest user question: {query}

Standalone question:"""

        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]

        try:
            response = llm.invoke(messages)
        except Exception:
            response = fallback_llm.invoke(messages)

        contextualized = response.content.strip().strip('"\'')

        if not contextualized:
            logger.warning("Contextualization returned empty, using original query")
            return query

        logger.info(f"Query contextualized:\nOriginal: {query}\nStandalone: {contextualized}")
        return contextualized

    except Exception as e:
        logger.error(f"Error during contextualization: {e}")
        return query


# ==================== SMART ROUTING SYSTEM ====================

def detect_intent_by_keywords(query: str) -> str:
    """
    –ë—ã—Å—Ç—Ä–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
    Returns: PRODUCT_SEARCH, KNOWLEDGE_BASE, ORDER_STATUS, GENERAL
    """
    query_lower = query.lower()

    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ç–æ–≤–∞—Ä–æ–≤
    product_keywords = [
        # –†—É—Å—Å–∫–∏–π
        '—Ü–µ–Ω–∞', '—Å—Ç–æ–∏–º–æ—Å—Ç—å', '—Å–∫–æ–ª—å–∫–æ —Å—Ç–æ–∏—Ç', '–∫—É–ø–∏—Ç—å', '–≤ –Ω–∞–ª–∏—á–∏–∏',
        '–µ—Å—Ç—å –ª–∏', '–Ω–∞–π–¥–∏', '–ø–æ–∫–∞–∂–∏ —Ç–æ–≤–∞—Ä', '—Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏', '–º–æ–¥–µ–ª—å',
        '–±—Ä–µ–Ω–¥', '–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å', '–ø–æ—Å–æ–≤–µ—Ç—É–π —Ç–æ–≤–∞—Ä', '—Ö–æ—á—É –∫—É–ø–∏—Ç—å',
        '–∫–∞–∫–æ–π —Ç–µ–ª–µ—Ñ–æ–Ω', '–∫–∞–∫–æ–π —Å–º–∞—Ä—Ç—Ñ–æ–Ω', '–Ω–æ—É—Ç–±—É–∫', '–ø–ª–∞–Ω—à–µ—Ç',
        # –ê–∑–µ—Ä–±–∞–π–¥–∂–∞–Ω—Å–∫–∏–π
        'qiym…ôt', 'd…ôy…ôr', 'ne√ß…ôy…ôdir', 'almaq', 'stokda',
        'tap', 'm…ôhsul g√∂st…ôr', 'x√ºsusiyy…ôtl…ôr', 'model',
        'brend', 'istehsal√ßƒ±', 'm…ôsl…ôh…ôt ver', 'hansƒ± telefon',
        # –ê–Ω–≥–ª–∏–π—Å–∫–∏–π
        'price', 'cost', 'how much', 'buy', 'in stock',
        'find product', 'show me', 'features', 'brand', 'which phone'
    ]

    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è Knowledge Base
    kb_keywords = [
        '–∫–∞–∫', '–≥–¥–µ', '–∫–æ–≥–¥–∞', '–ø–æ—á–µ–º—É', '—á—Ç–æ —Ç–∞–∫–æ–µ',
        '–¥–æ—Å—Ç–∞–≤–∫–∞', '–≤–æ–∑–≤—Ä–∞—Ç', '–æ–ø–ª–∞—Ç–∞', '–≥–∞—Ä–∞–Ω—Ç–∏—è',
        '√ßatdƒ±rƒ±lma', 'qaytarma', '√∂d…ôni≈ü', 'z…ôman…ôt',
        'delivery', 'return', 'payment', 'warranty',
        '–ø–æ–ª–∏—Ç–∏–∫–∞', '–ø—Ä–∞–≤–∏–ª–∞', '—É—Å–ª–æ–≤–∏—è',
        'siyas…ôt', 'qaydalar', '≈ü…ôrtl…ôr',
        'policy', 'rules', 'terms'
    ]

    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –∑–∞–∫–∞–∑–æ–≤
    order_keywords = [
        '–∑–∞–∫–∞–∑', 'sifari≈ü', 'order',
        '—Å—Ç–∞—Ç—É—Å', 'status', 'v…ôziyy…ôt',
        '–≥–¥–µ –º–æ–π –∑–∞–∫–∞–∑', 'track', 'izl…ôm…ôk',
        '–Ω–æ–º–µ—Ä –∑–∞–∫–∞–∑–∞', 'order number'
    ]

    # –ü–æ–¥—Å—á–µ—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π
    product_score = sum(1 for kw in product_keywords if kw in query_lower)
    kb_score = sum(1 for kw in kb_keywords if kw in query_lower)
    order_score = sum(1 for kw in order_keywords if kw in query_lower)

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –±—Ä–µ–Ω–¥–æ–≤ –∏ –º–æ–¥–µ–ª–µ–π (—É—Å–∏–ª–∏–≤–∞–µ–º product_score)
    product_patterns = [
        r'\b(iphone|–∞–π—Ñ–æ–Ω|ayfon)\b',
        r'\b(samsung|—Å–∞–º—Å—É–Ω–≥)\b',
        r'\b(xiaomi|—Å—è–æ–º–∏|≈üaomi)\b',
        r'\b(huawei|—Ö—É–∞–≤–µ–π)\b',
        r'\b(apple|—ç–ø–ø–ª)\b',
        r'\b\d+gb\b',  # –ø–∞–º—è—Ç—å
        r'\b(—Å–º–∞—Ä—Ç—Ñ–æ–Ω|smartphone|telefon)\b',
        r'\b(–Ω–æ—É—Ç–±—É–∫|laptop|noutbuk)\b',
        r'\b(–ø–ª–∞–Ω—à–µ—Ç|tablet|plan≈üet)\b',
        r'\b(–Ω–∞—É—à–Ω–∏–∫–∏|headphones|qulaqlƒ±q)\b',
        r'\b(—á–∞—Å—ã|watch|saat)\b',  # –î–û–ë–ê–í–õ–ï–ù–û
        r'\b(—Å–º–∞—Ä—Ç.?—á–∞—Å—ã|smart.?watch|aƒüƒ±llƒ± saat)\b',  # –î–û–ë–ê–í–õ–ï–ù–û
        r'\b(—Ñ–∏—Ç–Ω–µ—Å.?–±—Ä–∞—Å–ª–µ—Ç|fitness.?band|fitness.?tracker)\b',  # –î–û–ë–ê–í–õ–ï–ù–û
    ]

    for pattern in product_patterns:
        if re.search(pattern, query_lower):
            product_score += 2

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–∞–º–µ—Ä–µ–Ω–∏–µ –ø–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–º—É —Å—á–µ—Ç—É
    scores = {
        'PRODUCT_SEARCH': product_score,
        'KNOWLEDGE_BASE': kb_score,
        'ORDER_STATUS': order_score,
        'GENERAL': 0
    }

    max_score = max(scores.values())

    if max_score == 0:
        return 'GENERAL'

    return max(scores, key=scores.get)


def calculate_keyword_confidence(query: str) -> float:
    """
    –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
    Returns: 0.0 - 1.0
    """
    query_lower = query.lower()

    # –û—á–µ–Ω—å —è–≤–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã (confidence = 1.0)
    high_confidence_patterns = [
        r'—Å–∫–æ–ª—å–∫–æ —Å—Ç–æ–∏—Ç',
        r'ne√ß…ôy…ôdir',
        r'how much',
        r'–≤ –Ω–∞–ª–∏—á–∏–∏',
        r'stokda var',
        r'in stock',
        r'–≥–¥–µ –º–æ–π –∑–∞–∫–∞–∑',
        r'sifari≈üim harada',
        r'where is my order'
    ]

    for pattern in high_confidence_patterns:
        if re.search(pattern, query_lower):
            return 1.0

    # –ü–æ–¥—Å—á–µ—Ç –æ–±—â–µ–π —Å–∏–ª—ã —Å–∏–≥–Ω–∞–ª–æ–≤
    intent = detect_intent_by_keywords(query)

    # –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞: —á–µ–º –±–æ–ª—å—à–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤, —Ç–µ–º –≤—ã—à–µ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
    all_keywords = [
        '—Ü–µ–Ω–∞', 'qiym…ôt', 'price', '–∫—É–ø–∏—Ç—å', 'almaq', 'buy',
        '–¥–æ—Å—Ç–∞–≤–∫–∞', '√ßatdƒ±rƒ±lma', 'delivery', '–≤–æ–∑–≤—Ä–∞—Ç', 'qaytarma',
        '–∑–∞–∫–∞–∑', 'sifari≈ü', 'order', '–±–æ–Ω—É—Å', 'bonus'
    ]

    matches = sum(1 for kw in all_keywords if kw in query_lower)

    if matches >= 3:
        return 0.9
    elif matches >= 2:
        return 0.7
    elif matches >= 1:
        return 0.5
    else:
        return 0.3


def classify_query_with_llm(query: str) -> str:
    """
    –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –Ω–∞–º–µ—Ä–µ–Ω–∏—è —á–µ—Ä–µ–∑ LLM (–¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö —Å–ª—É—á–∞–µ–≤)
    """
    classification_prompt = f"""Classify the user's query intent for Birmarket marketplace support.

Choose ONE category:
- PRODUCT_SEARCH: questions about products, prices, availability, characteristics
- KNOWLEDGE_BASE: questions about delivery, returns, payment, policies, general info
- ORDER_STATUS: questions about order status, tracking
- GENERAL: greetings, thanks, casual conversation

User query: "{query}"

Response (ONE WORD ONLY):"""

    messages = [
        {"role": "system", "content": "You are a query classifier. Reply with only ONE word."},
        {"role": "user", "content": classification_prompt}
    ]

    try:
        response = llm.invoke(messages)
        intent = response.content.strip().upper()

        # –í–∞–ª–∏–¥–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞
        valid_intents = ['PRODUCT_SEARCH', 'KNOWLEDGE_BASE', 'ORDER_STATUS', 'GENERAL']
        if intent in valid_intents:
            logger.info(f"LLM classified intent: {intent}")
            return intent
        else:
            logger.warning(f"LLM returned invalid intent: {intent}, defaulting to GENERAL")
            return 'GENERAL'

    except Exception as e:
        logger.error(f"LLM classification failed: {e}")
        return 'GENERAL'


def smart_routing(user_query: str) -> str:
    """
    –£–º–Ω–∞—è –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è —Å –∫–æ–º–±–∏–Ω–∞—Ü–∏–µ–π –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –∏ LLM
    """
    # 1. –ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
    keyword_intent = detect_intent_by_keywords(user_query)
    keyword_confidence = calculate_keyword_confidence(user_query)

    logger.info(f"üîç Keyword intent: {keyword_intent} (confidence: {keyword_confidence:.2f})")

    # –ï—Å–ª–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤—ã—Å–æ–∫–∞—è (>0.8) - —Å—Ä–∞–∑—É —Ä–æ—É—Ç–∏–º
    if keyword_confidence > 0.8:
        logger.info(f"‚úÖ High confidence, routing to: {keyword_intent}")
        return keyword_intent

    # 2. –ï—Å–ª–∏ –Ω–µ —É–≤–µ—Ä–µ–Ω—ã - –∏—Å–ø–æ–ª—å–∑—É–µ–º LLM
    logger.info("ü§î Low confidence, consulting LLM...")
    llm_intent = classify_query_with_llm(user_query)

    # 3. –ï—Å–ª–∏ –Ω–∞–º–µ—Ä–µ–Ω–∏—è —Å–æ–≤–ø–∞–¥–∞—é—Ç - —Ç–æ—á–Ω–æ –ø—Ä–∞–≤–∏–ª—å–Ω–æ
    if keyword_intent == llm_intent:
        logger.info(f"‚úÖ Keyword and LLM agree: {llm_intent}")
        return llm_intent

    # 4. –ï—Å–ª–∏ —Ä–∞–∑–Ω—ã–µ - –¥–æ–≤–µ—Ä—è–µ–º LLM
    logger.info(f"‚ö†Ô∏è Mismatch! Keyword: {keyword_intent}, LLM: {llm_intent}. Trusting LLM.")
    return llm_intent


def extract_search_params(query: str) -> dict:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–∏—Å–∫–∞ –∏–∑ —Ç–µ–∫—Å—Ç–∞ –∑–∞–ø—Ä–æ—Å–∞
    """
    params = {}

    # –¶–µ–Ω–∞ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è
    price_patterns = [
        r'–¥–æ\s+(\d+)',
        r'maksimum\s+(\d+)',
        r'up to\s+(\d+)',
        r'–ø–æ–¥\s+(\d+)',
        r'–¥–µ—à–µ–≤–ª–µ\s+(\d+)',
        r'ucuz\s+(\d+)'
    ]

    for pattern in price_patterns:
        match = re.search(pattern, query, re.IGNORECASE)
        if match:
            params['max_price'] = float(match.group(1))
            break

    # –¶–µ–Ω–∞ –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è
    min_patterns = [
        r'–æ—Ç\s+(\d+)',
        r'minimum\s+(\d+)',
        r'from\s+(\d+)',
        r'd…ôn\s+(\d+)'
    ]

    for pattern in min_patterns:
        match = re.search(pattern, query, re.IGNORECASE)
        if match:
            params['min_price'] = float(match.group(1))
            break

    # –ù–∞–ª–∏—á–∏–µ
    stock_keywords = ['–≤ –Ω–∞–ª–∏—á–∏–∏', 'stokda', 'in stock', 'available', 'm√∂vcud']
    if any(kw in query.lower() for kw in stock_keywords):
        params['only_in_stock'] = True
    else:
        params['only_in_stock'] = False

    logger.info(f"üìä Extracted params: {params}")
    return params


# ==================== END SMART ROUTING ====================


def needs_human_handoff(response: str, context: str, query: str) -> bool:
    """
    –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, –Ω—É–∂–Ω–æ –ª–∏ –ü–†–ï–î–õ–û–ñ–ò–¢–¨ handoff (–Ω–µ —Å–æ–∑–¥–∞–≤–∞—Ç—å —Å—Ä–∞–∑—É!)

    Returns:
        True –µ—Å–ª–∏ –Ω—É–∂–Ω–æ –ø—Ä–µ–¥–ª–æ–∂–∏—Ç—å, False –µ—Å–ª–∏ –≤—Å—ë –û–ö
    """
    no_info_phrases = [
        "don't have exact information", "–Ω–µ—Ç —Ç–æ—á–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏", "–Ω–µ –∏–º–µ—é —Ç–æ—á–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏",
        "d…ôqiq m…ôlumat yoxdur", "recommend contacting", "—Ä–µ–∫–æ–º–µ–Ω–¥—É—é —Å–≤—è–∑–∞—Ç—å—Å—è",
        "unfortunately", "–∫ —Å–æ–∂–∞–ª–µ–Ω–∏—é", "t…ô…ôss√ºf ki", "not found", "–Ω–µ –Ω–∞–π–¥–µ–Ω–æ"
    ]

    # –ü—Ä—è–º–æ–π –∑–∞–ø—Ä–æ—Å –Ω–∞ handoff - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ
    handoff_direct_requests = [
        "—Ö–æ—á—É –ø–æ–≥–æ–≤–æ—Ä–∏—Ç—å —Å —á–µ–ª–æ–≤–µ–∫–æ–º", "—Å–æ–µ–¥–∏–Ω–∏—Ç–µ —Å –æ–ø–µ—Ä–∞—Ç–æ—Ä–æ–º",
        "–Ω—É–∂–µ–Ω –æ–ø–µ—Ä–∞—Ç–æ—Ä", "—Å–≤—è–∑–∞—Ç—å—Å—è —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π",
        "–ø–æ–≥–æ–≤–æ—Ä–∏—Ç—å —Å –º–µ–Ω–µ–¥–∂–µ—Ä–æ–º", "–∂–∏–≤–æ–π —á–µ–ª–æ–≤–µ–∫",
        "operator", "human", "support", "manager",
        "operatorla danƒ±≈ü", "insan lazƒ±m"
    ]

    response_lower = response.lower()
    query_lower = query.lower()

    # 1. –ü–†–Ø–ú–û–ô –∑–∞–ø—Ä–æ—Å –Ω–∞ handoff - –ù–ï –ø—Ä–µ–¥–ª–∞–≥–∞–µ–º, –∞ —Å—Ä–∞–∑—É —Å–æ–µ–¥–∏–Ω—è–µ–º
    if any(trigger in query_lower for trigger in handoff_direct_requests):
        return "direct"  # –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π –º–∞—Ä–∫–µ—Ä

    # 2. –ö–æ–Ω—Ç–µ–∫—Å—Ç —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π
    if len(context.strip()) < 50:
        return "offer"  # –ü—Ä–µ–¥–ª–æ–∂–∏—Ç—å

    # 3. –í –æ—Ç–≤–µ—Ç–µ –µ—Å—Ç—å —Ñ—Ä–∞–∑—ã "–Ω–µ –∑–Ω–∞—é"
    if any(phrase in response_lower for phrase in no_info_phrases):
        return "offer"

    # 4. –û—Ç–≤–µ—Ç —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π
    if len(response.strip()) < 30:
        return "offer"

    return False  # –í—Å—ë –û–ö, handoff –Ω–µ –Ω—É–∂–µ–Ω


def add_handoff_offer_to_response(response: str, user_lang: str) -> str:
    """
    –î–æ–±–∞–≤–ª—è–µ—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –æ handoff –∫ –æ—Ç–≤–µ—Ç—É AI

    Args:
        response: –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç AI
        user_lang: –Ø–∑—ã–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (ru, az, en)

    Returns:
        –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç —Å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ–º
    """
    offers = {
        'ru': "\n\n‚ùì –•–æ—Ç–∏—Ç–µ, —Å–æ–µ–¥–∏–Ω—é –≤–∞—Å —Å –æ–ø–µ—Ä–∞—Ç–æ—Ä–æ–º –¥–ª—è –±–æ–ª–µ–µ –¥–µ—Ç–∞–ª—å–Ω–æ–π –ø–æ–º–æ—â–∏?",
        'az': "\n\n‚ùì Daha …ôtraflƒ± k√∂m…ôk √º√ß√ºn sizi operatorla …ôlaq…ôl…ôndirm…ôyimi ist…ôyirsiniz?",
        'en': "\n\n‚ùì Would you like me to connect you with an operator for more detailed assistance?",
        'tr': "\n\n‚ùì Daha detaylƒ± yardƒ±m i√ßin sizi bir operat√∂rle baƒülamamƒ± ister misiniz?"
    }

    offer_text = offers.get(user_lang, offers['en'])
    return response + offer_text


def answer_query(
        query: str,
        user_id: str | None = None,
        session_id: str | None = None,
        history_last_n: int = 3
) -> tuple[str, list[Document], list[str], str]:
    """
    –û—Å–Ω–æ–≤–Ω–æ–π RAG —Å –¥–∏–∞–ª–æ–≥–æ–º, –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π feedback –∏ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π DWH.

    Returns:
        (–æ—Ç–≤–µ—Ç, reranked_docs, selected_files, feedback_id)
    """
    message_id = str(uuid.uuid4())
    normalized_query = normalize_query(query)

    user_lang = detect(query)
    logger.info(f"üåç Detected language: {user_lang}")

    # 1. –ö–æ–Ω—Ç–µ–∫—Å—Ç—É–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–ø—Ä–æ—Å–∞
    contextualized_query = contextualize_query(normalized_query, user_id)
    logger.info(f"Processing query (user_id: {user_id or 'no-user'}, session: {session_id or 'no-session'}): {query}")
    if contextualized_query != normalized_query:
        logger.info(f"‚Üí Contextualized to: {contextualized_query}")

    # ========== –ü–†–û–í–ï–†–ö–ê: –û–∂–∏–¥–∞–µ—Ç –ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è handoff? ==========
    # –í–ê–ñ–ù–û: –≠—Ç–æ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –ü–ï–†–ï–î –ª—é–±–æ–π –¥—Ä—É–≥–æ–π –ª–æ–≥–∏–∫–æ–π!
    pending_action = conversation_state.get_pending_action(user_id)

    if pending_action and pending_action["action_type"] == "handoff_confirmation":
        logger.info(f"üîî User {user_id} has pending handoff confirmation")

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–ª—É—á—à–µ–Ω–Ω—ã–π –º–µ—Ç–æ–¥ –ø–∞—Ä—Å–∏–Ω–≥–∞
        user_response = conversation_state.parse_user_response(query)

        # ========== –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–¨ –°–û–ì–õ–ê–°–ò–õ–°–Ø ==========
        if user_response == "yes":
            logger.info("‚úÖ User confirmed handoff, creating session...")

            # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ pending action
            action_data = pending_action["data"]

            # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –æ–ø–µ—Ä–∞—Ç–æ—Ä–∞
            extended_context = f"""‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
ü§ñ –ê–í–¢–û–ú–ê–¢–ò–ß–ï–°–ö–ò–ô –ü–ï–†–ï–í–û–î: –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø–æ–¥—Ç–≤–µ—Ä–¥–∏–ª –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å –ø–æ–º–æ—â–∏ –æ–ø–µ—Ä–∞—Ç–æ—Ä–∞
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

üìù –û–†–ò–ì–ò–ù–ê–õ–¨–ù–´–ô –í–û–ü–†–û–°:
{action_data["original_query"]}

ü§ñ –û–¢–í–ï–¢ AI (–ù–ï –ü–û–ú–û–ì):
{action_data["ai_response"][:500]}{'...' if len(action_data["ai_response"]) > 500 else ''}

üìö –ö–û–ù–¢–ï–ö–°–¢ –ò–ó –ë–ê–ó–´ –ó–ù–ê–ù–ò–ô:
{action_data["context"][:800]}{'...' if len(action_data["context"]) > 800 else ''}

üí° –ü–†–ò–ß–ò–ù–ê –ü–ï–†–ï–í–û–î–ê: –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø–æ–¥—Ç–≤–µ—Ä–¥–∏–ª –∑–∞–ø—Ä–æ—Å –Ω–∞ –ø–æ–º–æ—â—å –æ–ø–µ—Ä–∞—Ç–æ—Ä–∞
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
"""

            # –°–æ–∑–¥–∞—ë–º handoff —Å–µ—Å—Å–∏—é
            session_handoff_id = handoff.create_session(
                query=action_data["contextualized_query"],
                context=extended_context,
                user_id=user_id,
                user_phone=None,
                user_name=None,
                user_email=None
            )

            # –û—á–∏—â–∞–µ–º pending action
            conversation_state.clear_pending_action(user_id)

            # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
            response_lang = user_lang if user_lang else 'en'
            chat_url = f"http://localhost:8001/chat?session={session_handoff_id}"

            handoff_messages = {
                'ru': f"‚úÖ –û—Ç–ª–∏—á–Ω–æ! –°–æ–µ–¥–∏–Ω—è—é –≤–∞—Å —Å –æ–ø–µ—Ä–∞—Ç–æ—Ä–æ–º...\n\nüé´ –ù–æ–º–µ—Ä –æ–±—Ä–∞—â–µ–Ω–∏—è: #{session_handoff_id[:8].upper()}\n‚è±Ô∏è –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è: ~2-3 –º–∏–Ω—É—Ç—ã\n\nüîó –ß–∞—Ç –æ—Ç–∫—Ä–æ–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏:\n{chat_url}",
                'az': f"‚úÖ ∆èla! Sizi operatorla …ôlaq…ôl…ôndirir…ôm...\n\nüé´ M√ºraci…ôt n√∂mr…ôsi: #{session_handoff_id[:8].upper()}\n‚è±Ô∏è Orta g√∂zl…ôm…ô vaxtƒ±: ~2-3 d…ôqiq…ô\n\nüîó √áat avtomatik a√ßƒ±lacaq:\n{chat_url}",
                'en': f"‚úÖ Great! Connecting you with an operator...\n\nüé´ Ticket number: #{session_handoff_id[:8].upper()}\n‚è±Ô∏è Average wait time: ~2-3 minutes\n\nüîó Chat will open automatically:\n{chat_url}",
                'tr': f"‚úÖ Harika! Sizi operat√∂rle baƒülƒ±yorum...\n\nüé´ Ba≈üvuru numarasƒ±: #{session_handoff_id[:8].upper()}\n‚è±Ô∏è Ortalama bekleme s√ºresi: ~2-3 dakika\n\nüîó Sohbet otomatik a√ßƒ±lacak:\n{chat_url}"
            }

            final_response = handoff_messages.get(response_lang, handoff_messages['en'])

            stats.handoff_count += 1
            logger.info(f"‚úÖ HANDOFF CONFIRMED - Session: {session_handoff_id}")

            # –°–æ–∑–¥–∞–µ–º feedback —Å –ø–æ–º–µ—Ç–∫–æ–π handoff_triggered
            feedback_id = feedback_manager.create_pending_feedback(
                ticket_id=message_id,
                user_id=user_id,
                session_id=session_id,
                original_query=action_data["original_query"],
                contextualized_query=action_data["contextualized_query"],
                ai_response=final_response,
                category="handoff_confirmed",
                selected_files=[],
                from_cache=False,
                handoff_triggered=True
            )

            return final_response, [], [], feedback_id

        # ========== –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–¨ –û–¢–ö–ê–ó–ê–õ–°–Ø ==========
        elif user_response == "no":
            logger.info("‚ùå User declined handoff, continuing conversation...")

            # –û—á–∏—â–∞–µ–º pending action
            conversation_state.clear_pending_action(user_id)

            # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
            response_lang = user_lang if user_lang else 'en'

            decline_messages = {
                'ru': "–•–æ—Ä–æ—à–æ, —è –ø–æ—Å—Ç–∞—Ä–∞—é—Å—å –ø–æ–º–æ—á—å –≤–∞–º –¥–∞–ª—å—à–µ. –ß—Ç–æ –±—ã –≤—ã —Ö–æ—Ç–µ–ª–∏ —É–∑–Ω–∞—Ç—å?",
                'az': "Yax≈üƒ±, siz…ô k√∂m…ôk etm…ôy…ô davam ed…ôc…ôy…ôm. N…ô √∂yr…ônm…ôk ist…ôrdiniz?",
                'en': "Alright, I'll continue helping you. What would you like to know?",
                'tr': "Tamam, size yardƒ±mcƒ± olmaya devam edeceƒüim. Ne √∂ƒürenmek istersiniz?"
            }

            final_response = decline_messages.get(response_lang, decline_messages['en'])

            # –ù–ï —Å–æ–∑–¥–∞–µ–º feedback –¥–ª—è –æ—Ç–∫–∞–∑–∞ (—ç—Ç–æ —Å–ª—É–∂–µ–±–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ)
            return final_response, [], [], None

        # ========== –ù–ï–ü–û–ù–Ø–¢–ù–´–ô –û–¢–í–ï–¢ ==========
        else:  # user_response == "unclear"
            logger.warning("‚ö†Ô∏è User response unclear, asking again...")

            response_lang = user_lang if user_lang else 'en'

            clarification_messages = {
                'ru': "–ò–∑–≤–∏–Ω–∏—Ç–µ, —è –Ω–µ –ø–æ–Ω—è–ª –≤–∞—à –æ—Ç–≤–µ—Ç. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–≤–µ—Ç—å—Ç–µ '–î–∞' –∏–ª–∏ '–ù–µ—Ç':\n\n–•–æ—Ç–∏—Ç–µ —Å–æ–µ–¥–∏–Ω–∏—Ç—å—Å—è —Å –æ–ø–µ—Ä–∞—Ç–æ—Ä–æ–º?",
                'az': "Baƒüƒ±≈ülayƒ±n, cavabƒ±nƒ±zƒ± ba≈üa d√º≈üm…ôdim. Z…ôhm…ôt olmasa 'B…ôli' v…ô ya 'Xeyr' cavabƒ± verin:\n\nOperatorla …ôlaq…ô saxlamaq ist…ôyirsiniz?",
                'en': "Sorry, I didn't understand your answer. Please reply 'Yes' or 'No':\n\nWould you like to connect with an operator?",
                'tr': "√úzg√ºn√ºm, cevabƒ±nƒ±zƒ± anlayamadƒ±m. L√ºtfen 'Evet' veya 'Hayƒ±r' yanƒ±tƒ± verin:\n\nOperat√∂rle baƒülantƒ± kurmak ister misiniz?"
            }

            final_response = clarification_messages.get(response_lang, clarification_messages['en'])

            return final_response, [], [], None

    # ========== –û–ë–´–ß–ù–ê–Ø –û–ë–†–ê–ë–û–¢–ö–ê –ó–ê–ü–†–û–°–ê (–µ—Å–ª–∏ –Ω–µ—Ç pending action) ==========

    # ==================== SMART ROUTING ====================
    intent = smart_routing(contextualized_query)
    logger.info(f"üéØ Final routing decision: {intent}")

    # ==================== PRODUCT SEARCH (DWH) ====================
    if intent == "PRODUCT_SEARCH":
        logger.info("üõçÔ∏è Routing to DWH product search")

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–∏—Å–∫–∞
        search_params = extract_search_params(contextualized_query)

        # –ü–æ–∏—Å–∫ —Ç–æ–≤–∞—Ä–æ–≤ –≤ DWH
        products = dwh_search.search_products(
            query=contextualized_query,
            only_in_stock=search_params.get('only_in_stock', True),
            min_price=search_params.get('min_price'),
            max_price=search_params.get('max_price'),
        )

        if products:
            logger.info(f"‚úÖ Found {len(products)} products in DWH")
            products_context = dwh_search.format_products_for_llm(products, user_lang.lower())

            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ LLM —Å —Ç–æ–≤–∞—Ä–∞–º–∏
            messages = [
                {
                    "role": "system",
                    "content": (
                        f"You are a helpful shopping assistant for Birmarket marketplace.\n"
                        f"CRITICAL: You MUST respond ONLY in user's language.\n"
                        f"Answer questions about products based on the provided catalog data.\n"
                        f"Be friendly, concise, and helpful.\n"
                        f"ALWAYS mention: price, availability, seller name.\n"
                        f"If multiple products match - show up to {len(products)} products, but keep descriptions concise.\n"
                        f"Do not offer something extra at the end of the answer."
                    )
                },
                {
                    "role": "user",
                    "content": (
                        f"Available products:\n{products_context}\n\n"
                        f"User question: {query}\n\n"
                    )
                }
            ]

            try:
                response = llm.invoke(messages)
            except Exception:
                response = fallback_llm.invoke(messages)

            final_response = response.content

            # –ü–æ–¥—Å—á–µ—Ç —Ç–æ–∫–µ–Ω–æ–≤
            usage = response.response_metadata.get("usage", {})
            prompt_tokens = usage.get("prompt_tokens", 0)
            completion_tokens = usage.get("completion_tokens", 0)
            total_tokens = prompt_tokens + completion_tokens
            if total_tokens == 0:
                total_tokens = int(len((products_context + query + final_response).split()) * 1.3)

            stats.spent_tokens += total_tokens
            stats.llm_calls += 1

            if user_id:
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
                chat_history.add_message(user_id, "user", query, metadata={"contextualized": contextualized_query})

                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
                chat_history.add_message(user_id, "assistant", final_response,
                                         metadata={"tokens": total_tokens, "message_id": message_id})

            # –°–æ–∑–¥–∞–µ–º feedback
            feedback_id = feedback_manager.create_pending_feedback(
                ticket_id=message_id,
                user_id=user_id,
                session_id=session_id,
                original_query=query,
                contextualized_query=contextualized_query,
                ai_response=final_response,
                category="product_search",
                selected_files=[],
                from_cache=False,
                handoff_triggered=False
            )

            logger.info("‚úÖ Product search completed successfully")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç—ã–µ docs —Ç.–∫. –¥–∞–Ω–Ω—ã–µ –∏–∑ DWH, –Ω–µ –∏–∑ —Ñ–∞–π–ª–æ–≤
            return final_response, [], [], feedback_id
        else:
            # –¢–æ–≤–∞—Ä—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã - –ø–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ –æ–±—ã—á–Ω—ã–π RAG (–º–æ–∂–µ—Ç –±—ã—Ç—å –æ–±—â–∏–π –≤–æ–ø—Ä–æ—Å)
            logger.warning("‚ö†Ô∏è No products found in DWH, falling back to Knowledge Base")
            intent = "KNOWLEDGE_BASE"

    # ==================== ORDER STATUS ====================
    if intent == "ORDER_STATUS":
        logger.info("üì¶ Routing to ORDER_STATUS handler")
        # TODO: –ó–¥–µ—Å—å –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å —Å–∏—Å—Ç–µ–º–æ–π –∑–∞–∫–∞–∑–æ–≤
        # –ü–æ–∫–∞ –æ—Ç–≤–µ—á–∞–µ–º —á–µ—Ä–µ–∑ RAG –∏–ª–∏ handoff
        response = "–î–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å—Ç–∞—Ç—É—Å–∞ –∑–∞–∫–∞–∑–∞, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, —É–∫–∞–∂–∏—Ç–µ –Ω–æ–º–µ—Ä –≤–∞—à–µ–≥–æ –∑–∞–∫–∞–∑–∞ –∏–ª–∏ —Å–æ–µ–¥–∏–Ω—é –≤–∞—Å —Å–æ —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–æ–º."

        return response, [], [], None

    # ==================== GENERAL (casual chat) ====================
    if intent == "GENERAL":
        logger.info("üí¨ General conversation detected")

        # –ü—Ä–æ—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –±–µ–∑ retrieval –¥–ª—è –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–π/–±–ª–∞–≥–æ–¥–∞—Ä–Ω–æ—Å—Ç–µ–π
        casual_patterns = [
            r'\b(–ø—Ä–∏–≤–µ—Ç|–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π|hi|hello|salam)\b',
            r'\b(–ö–∞–∫ –¥–µ–ª–∞?|–ö–∞–∫ –≤–∞—à–∏ –¥–µ–ª–∞?|how are you?|nec…ôsiz|necesiz)\b',
            r'\b(—Å–ø–∞—Å–∏–±–æ|thanks|t…ô≈ü…ôkk√ºr|–º–µ—Ä—Å–∏)\b',
            r'\b(–ø–æ–∫–∞|bye|goodbye|saƒüol)\b'
        ]

        is_casual = any(re.search(p, query.lower()) for p in casual_patterns)

        if is_casual:
            messages = [{
                "role": "system",
                "content": (
                    f"You are a friendly Birmarket support assistant.\n"
                    f'If there is a choise between turkish or Azerbaijani - use JUST Azerbaijani.\n'
                    f"CRITICAL: Respond ONLY in user's language.\n"
                    f"Be warm and brief."
                )
            }, {
                "role": "user",
                "content": f"User message: {query}"
            }]

            try:
                response = llm.invoke(messages)
            except Exception:
                response = fallback_llm.invoke(messages)

            final_response = response.content

            return final_response, [], [], None

        # –ï—Å–ª–∏ –Ω–µ —Å–æ–≤—Å–µ–º casual - –∏—â–µ–º –≤ Knowledge Base
        intent = "KNOWLEDGE_BASE"

    # ==================== KNOWLEDGE BASE (RAG) ====================
    if intent == "KNOWLEDGE_BASE":
        logger.info("üìö Routing to Knowledge Base (RAG)")

        # 2. –ì–∏–±—Ä–∏–¥–Ω—ã–π retrieval
        summary_docs = hybrid_summary_search(contextualized_query, top_k=30)
        selected_files = [doc.metadata["file"] for doc in summary_docs]

        # 3. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–µ—Ç–∞–ª—å–Ω—ã—Ö —á–∞–Ω–∫–æ–≤
        chunks_dir = Path("/home/user/PyCharmMiscProject/RAG/chunks")
        detailed_docs = []
        for file_name in selected_files:
            file_path = chunks_dir / file_name
            if file_path.exists():
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                    detailed_docs.append(
                        Document(
                            page_content=content,
                            metadata={"source": file_name, "type": "detailed_chunk"}
                        )
                    )

        if not detailed_docs:
            response = "–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, –Ω–µ –Ω–∞—à—ë–ª —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–æ –≤–∞—à–µ–º—É –≤–æ–ø—Ä–æ—Å—É."

            if user_id:
                chat_history.add_message(user_id, "user", query, metadata={"contextualized": contextualized_query})
                chat_history.add_message(user_id, "assistant", response, metadata={"no_relevant_docs": True})

            feedback_id = feedback_manager.create_pending_feedback(
                ticket_id=message_id,
                user_id=user_id,
                session_id=session_id,
                original_query=query,
                contextualized_query=contextualized_query,
                ai_response=response,
                category="knowledge_base",
                selected_files=[],
                from_cache=False,
                handoff_triggered=False
            )

            return response, [], selected_files, feedback_id

        # 4. Rerank —á–µ—Ä–µ–∑ FlashRank
        class SimpleRetriever(BaseRetriever):
            docs: list

            def _get_relevant_documents(self, query: str, **kwargs):
                return self.docs

        temp_retriever = SimpleRetriever(docs=detailed_docs)
        compression_retriever = ContextualCompressionRetriever(
            base_compressor=summary_compressor,
            base_retriever=temp_retriever
        )
        reranked_docs = compression_retriever.invoke(contextualized_query)

        # 5. –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
        context = "\n\n".join(doc.page_content for doc in reranked_docs)

        # 6. –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –∫—ç—à
        from_cache = False
        cached_doc = semantic_cache.retrieve_cached_response(contextualized_query)
        if cached_doc:
            stats.cache_hits += 1
            cached_tokens = cached_doc.metadata.get("tokens", 0)
            stats.saved_tokens += cached_tokens
            logger.info("‚úÖ From Semantic Cache")

            final_response = cached_doc.metadata["response"]
            from_cache = True

            if user_id:
                chat_history.add_message(user_id, "user", query, metadata={"contextualized": contextualized_query})
                chat_history.add_message(user_id, "assistant", cached_doc.metadata["response"],
                                         metadata={"from_cache": True})

            feedback_id = feedback_manager.create_pending_feedback(
                ticket_id=message_id,
                user_id=user_id,
                session_id=session_id,
                original_query=query,
                contextualized_query=contextualized_query,
                ai_response=final_response,
                category="knowledge_base",
                selected_files=selected_files,
                from_cache=True,
                handoff_triggered=False
            )

            return final_response, reranked_docs, selected_files, feedback_id

        # 7. –ó–∞–ø—Ä–æ—Å –∫ LLM
        logger.info("ü§ñ Request to Azure OpenAI")
        stats.llm_calls += 1

        messages = [
            {
                "role": "system",
                "content": "You are a friendly, warm, and professional AI assistant for Birmarket customer support ‚Äî an online marketplace operating in Azerbaijan.\n\n" +
                           "CORE PRINCIPLES:\n" +
                           "‚Ä¢ Answer strictly based on the provided context.\n" +
                           "‚Ä¢ If the needed information is missing from the context ‚Äî honestly say: 'Unfortunately, I don't have the exact information on this.'\n" +
                           "‚Ä¢ NEVER invent, guess, or assume facts about Birmarket, prices, delivery times, product availability, policies, or any other details.\n\n" +
                           "ALLOWED SMALL TALK (answer naturally and kindly):\n" +
                           "‚Ä¢ Greetings (salam, hi, hello, good day, etc.)\n" +
                           "‚Ä¢ Questions about language ('Can I speak Russian?', 'English?', 'Az…ôrbaycanca?')\n" +
                           "‚Ä¢ Thanks and polite phrases ('t…ô≈ü…ôkk√ºr', 'thank you')\n" +
                           "‚Ä¢ Casual questions like 'How are you?', 'What can you do?'\n" +
                           "‚Ä¢ Requests to repeat or explain something again\n\n" +
                           "LANGUAGE & TONE RULES:\n" +
                           "‚Ä¢ Be ready to answer ONLY in Russian, Azerbaijani, English, or Turkish ‚Äî whichever the user chooses.\n" +
                           "‚Ä¢ If the context contains useful information in Azerbaijani ‚Äî use it and translate the relevant parts accurately into the user's language.\n" +
                           "‚Ä¢ Speak politely, warmly, and concisely ‚Äî like a friendly and competent shop assistant.\n" +
                           "‚Ä¢ Use respectful 'You' / 'siz' form unless the customer clearly switches to informal 'you' / 's…ôn' first.\n" +
                           "‚Ä¢ If client talk you to connect him with operator - do not say something extra, just 'Of course.'.\n" +
                           "‚Ä¢ Keep answers short but complete ‚Äî enough for the customer to clearly understand.\n\n" +
                           "STRICT BOUNDARIES:\n" +
                           "‚Ä¢ You are NOT a general-purpose AI. If the question is clearly outside Birmarket support (politics, weather, programming, personal advice, religion, relationships, etc.) ‚Äî politely redirect: 'Sorry, I specialize only in helping with purchases and Birmarket services. For other topics I recommend using other resources.'\n" +
                           "‚Ä¢ Never discuss your own nature, model, training, xAI, Grok, or any internal details.\n" +
                           "‚Ä¢ Avoid excessive apologies or self-deprecating phrases unless there is a real reason.\n\n" +
                           "‚Ä¢ Your main goal: Help customers quickly, clearly, and pleasantly with anything related to shopping on Birmarket."
            },
            {
                "role": "user",
                "content": f"Context:\n{context}\n\nQuestion: {query}"
            }
        ]

        try:
            response = llm.invoke(messages)
        except Exception:
            response = fallback_llm.invoke(messages)

        # –ü–æ–¥—Å—á—ë—Ç —Ç–æ–∫–µ–Ω–æ–≤
        usage = response.response_metadata.get("usage", {})
        prompt_tokens = usage.get("prompt_tokens", 0)
        completion_tokens = usage.get("completion_tokens", 0)
        total_tokens = prompt_tokens + completion_tokens
        if total_tokens == 0:
            total_tokens = int(len((context + contextualized_query + response.content).split()) * 1.3)
        stats.spent_tokens += total_tokens

        final_response = response.content
        handoff_triggered = False

        # 8. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏ (–î–û handoff –ª–æ–≥–∏–∫–∏)
        if user_id:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            chat_history.add_message(
                user_id,
                "user",
                query,
                metadata={"contextualized": contextualized_query}
            )

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
            chat_history.add_message(
                user_id,
                "assistant",
                final_response,
                metadata={
                    "tokens": total_tokens,
                    "message_id": message_id
                }
            )

        # ========== –ü–†–û–í–ï–†–ö–ê –ù–£–ñ–ï–ù –õ–ò HANDOFF ==========
        handoff_decision = needs_human_handoff(final_response, context, query)

        if handoff_decision == "direct":
            # –ü–†–Ø–ú–û–ô –∑–∞–ø—Ä–æ—Å - —Å–æ–µ–¥–∏–Ω—è–µ–º —Å—Ä–∞–∑—É –±–µ–∑ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è
            logger.info("üî¥ DIRECT handoff request detected")

            extended_context = f"""‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
ü§ñ –ü–†–Ø–ú–û–ô –ó–ê–ü–†–û–° –ù–ê –û–ü–ï–†–ê–¢–û–†–ê
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

üìù –ó–ê–ü–†–û–° –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø:
{query}

üìö –ö–û–ù–¢–ï–ö–°–¢:
{context[:800]}{'...' if len(context) > 800 else ''}

üí° –ü–†–ò–ß–ò–ù–ê: –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–∞–ø—Ä—è–º—É—é –∑–∞–ø—Ä–æ—Å–∏–ª —Å–≤—è–∑—å —Å –æ–ø–µ—Ä–∞—Ç–æ—Ä–æ–º
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
"""

            session_handoff_id = handoff.create_session(
                query=contextualized_query,
                context=extended_context,
                user_id=user_id,
                user_phone=None,
                user_name=None,
                user_email=None
            )

            response_lang = user_lang if user_lang else 'en'
            chat_url = f"http://localhost:8001/chat?session={session_handoff_id}"

            handoff_messages = {
                'ru': f"‚úÖ –ö–æ–Ω–µ—á–Ω–æ! –°–æ–µ–¥–∏–Ω—è—é –≤–∞—Å —Å –æ–ø–µ—Ä–∞—Ç–æ—Ä–æ–º...\n\nüé´ –ù–æ–º–µ—Ä –æ–±—Ä–∞—â–µ–Ω–∏—è: #{session_handoff_id[:8].upper()}\n‚è±Ô∏è –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è: ~2-3 –º–∏–Ω—É—Ç—ã\n\nüîó –ß–∞—Ç:\n{chat_url}",
                'az': f"‚úÖ ∆èlb…ôtt…ô! Sizi operatorla …ôlaq…ôl…ôndirir…ôm...\n\nüé´ M√ºraci…ôt n√∂mr…ôsi: #{session_handoff_id[:8].upper()}\n‚è±Ô∏è Orta g√∂zl…ôm…ô vaxtƒ±: ~2-3 d…ôqiq…ô\n\nüîó √áat:\n{chat_url}",
                'en': f"‚úÖ Of course! Connecting you with an operator...\n\nüé´ Ticket: #{session_handoff_id[:8].upper()}\n‚è±Ô∏è Wait time: ~2-3 min\n\nüîó Chat:\n{chat_url}"
            }

            final_response = handoff_messages.get(response_lang, handoff_messages['en'])
            stats.handoff_count += 1
            handoff_triggered = True

        elif handoff_decision == "offer":
            # –ü–†–ï–î–õ–û–ñ–ò–¢–¨ handoff - —Å–æ–∑–¥–∞–µ–º pending action
            logger.info("üü° Handoff needed, creating confirmation request")

            # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –∫ –æ—Ç–≤–µ—Ç—É
            final_response = add_handoff_offer_to_response(final_response, user_lang)

            # –°–æ–∑–¥–∞–µ–º pending action
            conversation_state.create_handoff_confirmation(
                user_id=user_id,
                original_query=query,
                contextualized_query=contextualized_query,
                ai_response=final_response,
                context=context,
                ttl_minutes=10
            )

            logger.info(f"‚è≥ Waiting for user confirmation (user_id: {user_id})")

        else:
            # –í—Å—ë –û–ö, –∫—ç—à–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
            semantic_cache.store_response(contextualized_query, final_response, total_tokens)
            stats.cached_responses += 1
            logger.info("‚úÖ Response cached")

        # –°–æ–∑–¥–∞–µ–º feedback
        feedback_id = feedback_manager.create_pending_feedback(
            ticket_id=message_id,
            user_id=user_id,
            session_id=session_id,
            original_query=query,
            contextualized_query=contextualized_query,
            ai_response=final_response,
            category="knowledge_base",
            selected_files=selected_files,
            from_cache=from_cache,
            handoff_triggered=handoff_triggered
        )

        return final_response, reranked_docs, selected_files, feedback_id

    # –ï—Å–ª–∏ –ø–æ–ø–∞–ª–∏ —Å—é–¥–∞ - —á—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –¥–µ—Ñ–æ–ª—Ç
    return "–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.", [], [], None

__all__ = ["answer_query"]