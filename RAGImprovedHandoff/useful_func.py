import re
from llm import llm, fallback_llm
from logger_setup import setup_logger
from chat_history_manager import chat_history

logger = setup_logger()

BUSINESS_ENTITIES = {
    "birbonus": [
        "–±–∏—Ä–±–æ–Ω—É—Å", "–±–∏—Ä –±–æ–Ω—É—Å", "birbonus", "bir bomus",
        "bir-bonus", "birbonuz",
    ],
    "birmarket": [
        "–±–∏—Ä–º–∞—Ä–∫–µ—Ç", "–±–∏—Ä –º–∞—Ä–∫–µ—Ç", "birmarket", "bir market",
        "birmarkat", "bir-market",
    ],
}

def detect_lang(query: str) -> str:
    """
    –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏—á–µ—Å–∫–∞—è –¥–µ—Ç–µ–∫—Ü–∏—è —è–∑—ã–∫–∞: –∞–∑–µ—Ä–±–∞–π–¥–∂–∞–Ω—Å–∫–∏–π –∏–ª–∏ —Ä—É—Å—Å–∫–∏–π.
    """
    query_lower = query.lower()

    az_letters = "q√ºertui√∂ƒü…ôƒ±l≈ü√ßmnvbzsdfghjkl"
    ru_letters = "–π—Ü—É–∫–µ–Ω–≥—à—â–∑—Ö—ä—Ñ—ã–∂–≤—ç–∞–¥–ª–ø–æ—Ä—è—á—Å—Ç–º—å–∏–±—é"

    if any(letter in query_lower for letter in az_letters):
        return 'az'
    if any(letter in query_lower for letter in ru_letters):
        return 'ru'

    return 'en'


def normalize_query(query: str) -> str:
    """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–ø—Ä–æ—Å–∞ —Å –∑–∞–º–µ–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –Ω–∞–∑–≤–∞–Ω–∏–π"""
    q = query.lower()
    for canonical, variants in BUSINESS_ENTITIES.items():
        for v in variants:
            q = re.sub(rf"\b{re.escape(v)}\b", canonical, q)
    return q


def contextualize_query(query: str, user_id: str | None) -> str:
    """
    –ü–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä—É–µ—Ç –∑–∞–ø—Ä–æ—Å –≤ —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω—ã–π, –µ—Å–ª–∏ –æ–Ω —Å—Å—ã–ª–∞–µ—Ç—Å—è –Ω–∞ –∏—Å—Ç–æ—Ä–∏—é.
    """
    if not user_id:
        return query

    try:
        history = chat_history.get_history(user_id)
        recent_messages = history[-6:]  # –ø–æ—Å–ª–µ–¥–Ω–∏–µ 6 —Å–æ–æ–±—â–µ–Ω–∏–π (user + assistant)

        if not recent_messages:
            return query

        # –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Å—Ç–æ—Ä–∏—é —Å —Ä–æ–ª—è–º–∏
        history_text = []
        for msg in recent_messages:
            role = "User" if msg.role == "user" else "Assistant"
            history_text.append(f"{role}: {msg.content}")
        history_text = "\n".join(history_text)

        system_prompt = (
            "You are a helpful assistant that reformulates the latest user question "
            "into a standalone question that can be fully understood without the chat history. "
            "You work in customer support for Birmarket (online marketplace in Azerbaijan). "
            "INSTRUCTIONS:\n"
            "- Reformulate ONLY if the question refers to previous context "
            "(e.g. '—ç—Ç–æ', '–æ–Ω', '—Ç–∞ —Ç–æ–≤–∞—Ä', 'bu', 'o', 'h…ômin', '—Å–∫–æ–ª—å–∫–æ —Å—Ç–æ–∏—Ç?', etc.).\n"
            "- If it's a continuation ('–¥–∞', '—Ä–∞—Å—Å–∫–∞–∂–∏ –ø–æ–¥—Ä–æ–±–Ω–µ–µ', 'yes, more') ‚Äî keep reference to previous topic.\n"
            "- Keep the SAME language as the latest question.\n"
            "- DO NOT answer the question ‚Äî only return the standalone version.\n"
            "- If the question is already independent ‚Äî return it AS IS.\n"
            "- Do not add any explanations."
        )

        user_prompt = f"""Chat history (user questions only):
{history_text}

Latest user question: {query}

Standalone question:"""

        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]

        try:
            response = llm.invoke(messages)
        except Exception:
            response = fallback_llm.invoke(messages)

        contextualized = response.content.strip().strip('"\'')

        if not contextualized:
            logger.warning("Contextualization returned empty, using original query")
            return query

        logger.info(f"Query contextualized:\nOriginal: {query}\nStandalone: {contextualized}")
        return contextualized

    except Exception as e:
        logger.error(f"Error during contextualization: {e}")
        return query


# ==================== SMART ROUTING SYSTEM ====================

def classify_query_with_llm(query: str) -> str:
    """
    –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –Ω–∞–º–µ—Ä–µ–Ω–∏—è —á–µ—Ä–µ–∑ LLM (–¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö —Å–ª—É—á–∞–µ–≤)
    """
    classification_prompt = f"""Classify the user's query intent for Birmarket marketplace support.

Choose ONE category:
- PRODUCT_SEARCH: questions about products, prices, availability, characteristics
- KNOWLEDGE_BASE: questions about delivery, returns, payment, policies, general info
- ORDER_STATUS: questions about order status, tracking
- GENERAL: greetings, thanks, casual conversation

User query: "{query}"

Response (ONE WORD ONLY):"""

    messages = [
        {"role": "system", "content": "You are a query classifier. Reply with only ONE word."},
        {"role": "user", "content": classification_prompt}
    ]

    try:
        response = llm.invoke(messages)
        intent = response.content.strip().upper()

        # –í–∞–ª–∏–¥–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞
        valid_intents = ['PRODUCT_SEARCH', 'KNOWLEDGE_BASE', 'ORDER_STATUS', 'GENERAL']
        if intent in valid_intents:
            logger.info(f"LLM classified intent: {intent}")
            return intent
        else:
            logger.warning(f"LLM returned invalid intent: {intent}, defaulting to GENERAL")
            return 'GENERAL'

    except Exception as e:
        logger.error(f"LLM classification failed: {e}")
        return 'GENERAL'


def extract_search_params(query: str) -> dict:
    """
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–∏—Å–∫–∞ –∏–∑ —Ç–µ–∫—Å—Ç–∞ –∑–∞–ø—Ä–æ—Å–∞
    """
    params = {}

    # –¶–µ–Ω–∞ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è
    price_patterns = [
        r'–¥–æ\s+(\d+)',
        r'maksimum\s+(\d+)',
        r'up to\s+(\d+)',
        r'–ø–æ–¥\s+(\d+)',
        r'–¥–µ—à–µ–≤–ª–µ\s+(\d+)',
        r'ucuz\s+(\d+)'
    ]

    for pattern in price_patterns:
        match = re.search(pattern, query, re.IGNORECASE)
        if match:
            params['max_price'] = float(match.group(1))
            break

    # –¶–µ–Ω–∞ –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è
    min_patterns = [
        r'–æ—Ç\s+(\d+)',
        r'minimum\s+(\d+)',
        r'from\s+(\d+)',
        r'd…ôn\s+(\d+)'
    ]

    for pattern in min_patterns:
        match = re.search(pattern, query, re.IGNORECASE)
        if match:
            params['min_price'] = float(match.group(1))
            break

    # –ù–∞–ª–∏—á–∏–µ
    stock_keywords = ['–≤ –Ω–∞–ª–∏—á–∏–∏', 'stokda', 'in stock', 'available', 'm√∂vcud']
    if any(kw in query.lower() for kw in stock_keywords):
        params['only_in_stock'] = True
    else:
        params['only_in_stock'] = False

    logger.info(f"üìä Extracted params: {params}")
    return params


# ==================== END SMART ROUTING ====================


def needs_human_handoff(response: str, context: str, query: str) -> bool:
    """
    –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, –Ω—É–∂–Ω–æ –ª–∏ –ü–†–ï–î–õ–û–ñ–ò–¢–¨ handoff (–Ω–µ —Å–æ–∑–¥–∞–≤–∞—Ç—å —Å—Ä–∞–∑—É!)

    Returns:
        True –µ—Å–ª–∏ –Ω—É–∂–Ω–æ –ø—Ä–µ–¥–ª–æ–∂–∏—Ç—å, False –µ—Å–ª–∏ –≤—Å—ë –û–ö
    """
    no_info_phrases = [
        "don't have exact information", "–Ω–µ—Ç —Ç–æ—á–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏", "–Ω–µ –∏–º–µ—é —Ç–æ—á–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏",
        "d…ôqiq m…ôlumat yoxdur", "recommend contacting", "—Ä–µ–∫–æ–º–µ–Ω–¥—É—é —Å–≤—è–∑–∞—Ç—å—Å—è",
        "unfortunately", "–∫ —Å–æ–∂–∞–ª–µ–Ω–∏—é", "t…ô…ôss√ºf ki", "not found", "–Ω–µ –Ω–∞–π–¥–µ–Ω–æ"
    ]

    # –ü—Ä—è–º–æ–π –∑–∞–ø—Ä–æ—Å –Ω–∞ handoff - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ
    handoff_direct_requests = [
        "—Ö–æ—á—É –ø–æ–≥–æ–≤–æ—Ä–∏—Ç—å —Å —á–µ–ª–æ–≤–µ–∫–æ–º", "—Å–æ–µ–¥–∏–Ω–∏—Ç–µ —Å –æ–ø–µ—Ä–∞—Ç–æ—Ä–æ–º",
        "–Ω—É–∂–µ–Ω –æ–ø–µ—Ä–∞—Ç–æ—Ä", "—Å–≤—è–∑–∞—Ç—å—Å—è —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π",
        "–ø–æ–≥–æ–≤–æ—Ä–∏—Ç—å —Å –º–µ–Ω–µ–¥–∂–µ—Ä–æ–º", "–∂–∏–≤–æ–π —á–µ–ª–æ–≤–µ–∫",
        "operator", "human", "support", "manager",
        "operatorla danƒ±≈ü", "insan lazƒ±m"
    ]

    response_lower = response.lower()
    query_lower = query.lower()

    # 1. –ü–†–Ø–ú–û–ô –∑–∞–ø—Ä–æ—Å –Ω–∞ handoff - –ù–ï –ø—Ä–µ–¥–ª–∞–≥–∞–µ–º, –∞ —Å—Ä–∞–∑—É —Å–æ–µ–¥–∏–Ω—è–µ–º
    if any(trigger in query_lower for trigger in handoff_direct_requests):
        return "direct"  # –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π –º–∞—Ä–∫–µ—Ä

    # 2. –ö–æ–Ω—Ç–µ–∫—Å—Ç —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π
    if len(context.strip()) < 50:
        return "offer"  # –ü—Ä–µ–¥–ª–æ–∂–∏—Ç—å

    # 3. –í –æ—Ç–≤–µ—Ç–µ –µ—Å—Ç—å —Ñ—Ä–∞–∑—ã "–Ω–µ –∑–Ω–∞—é"
    if any(phrase in response_lower for phrase in no_info_phrases):
        return "offer"

    # 4. –û—Ç–≤–µ—Ç —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π
    if len(response.strip()) < 30:
        return "offer"

    return False  # –í—Å—ë –û–ö, handoff –Ω–µ –Ω—É–∂–µ–Ω


def add_handoff_offer_to_response(response: str, user_lang: str) -> str:
    """
    –î–æ–±–∞–≤–ª—è–µ—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –æ handoff –∫ –æ—Ç–≤–µ—Ç—É AI

    Args:
        response: –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç AI
        user_lang: –Ø–∑—ã–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (ru, az, en)

    Returns:
        –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç —Å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ–º
    """
    offers = {
        'ru': "\n\n‚ùì –•–æ—Ç–∏—Ç–µ, —Å–æ–µ–¥–∏–Ω—é –≤–∞—Å —Å –æ–ø–µ—Ä–∞—Ç–æ—Ä–æ–º –¥–ª—è –±–æ–ª–µ–µ –¥–µ—Ç–∞–ª—å–Ω–æ–π –ø–æ–º–æ—â–∏?",
        'az': "\n\n‚ùì Daha …ôtraflƒ± k√∂m…ôk √º√ß√ºn sizi operatorla …ôlaq…ôl…ôndirm…ôyimi ist…ôyirsiniz?",
    }

    offer_text = offers.get(user_lang, offers['az'])
    return response + offer_text