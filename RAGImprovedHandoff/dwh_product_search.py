import pandas as pd
import pyarrow.parquet as pq
import redis
import json
import hashlib
from typing import List, Dict, Optional
from pathlib import Path
from datetime import datetime
from azure.identity import DefaultAzureCredential
from azure.storage.blob import BlobServiceClient
from logger_setup import setup_logger

logger = setup_logger()


class DWHCache:
    """–ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞ –≤ Redis"""

    def __init__(self, redis_client: redis.Redis):
        self.redis = redis_client
        self.ttl = 1800  # 30 –º–∏–Ω—É—Ç
        self.prefix = "dwh_product_cache:"

    def get_cache_key(self, query: str, filters: dict) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫–ª—é—á –∫—ç—à–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∑–∞–ø—Ä–æ—Å–∞ –∏ —Ñ–∏–ª—å—Ç—Ä–æ–≤"""
        data = f"{query}_{json.dumps(filters, sort_keys=True)}"
        hash_key = hashlib.md5(data.encode()).hexdigest()
        return f"{self.prefix}{hash_key}"

    def get(self, query: str, filters: dict) -> Optional[List[Dict]]:
        """–ü–æ–ª—É—á–∞–µ—Ç –∑–∞–∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã"""
        key = self.get_cache_key(query, filters)
        try:
            cached = self.redis.get(key)
            if cached:
                logger.info(f"‚úÖ DWH Cache HIT for query: {query[:50]}")
                return json.loads(cached)
        except Exception as e:
            logger.error(f"Cache get error: {e}")
        return None

    def set(self, query: str, filters: dict, results: List[Dict]):
        """–ö—ç—à–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã"""
        key = self.get_cache_key(query, filters)
        try:
            self.redis.setex(key, self.ttl, json.dumps(results, default=str))
            logger.info(f"üíæ Results cached for query: {query[:50]}")
        except Exception as e:
            logger.error(f"Cache set error: {e}")


class AzureParquetLoader:
    """–ó–∞–≥—Ä—É–∑—á–∏–∫ Parquet —Ñ–∞–π–ª–æ–≤ –∏–∑ Azure Storage"""

    def __init__(
            self,
            storage_account_name: str,
            container_name: str,
            blob_path: str,
            use_managed_identity: bool = True,
            connection_string: Optional[str] = None
    ):
        self.storage_account_name = storage_account_name
        self.container_name = container_name
        self.blob_path = blob_path
        self.local_cache_path = Path("/tmp/dwh_products_cache.parquet")
        self.df = None
        self.last_loaded = None

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Azure Blob Client
        if use_managed_identity:
            # Managed Identity (–¥–ª—è production –≤ Azure)
            credential = DefaultAzureCredential()
            account_url = f"https://{storage_account_name}.blob.core.windows.net"
            self.blob_service_client = BlobServiceClient(account_url, credential=credential)
        elif connection_string:
            # Connection String (–¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–π —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏)
            self.blob_service_client = BlobServiceClient.from_connection_string(connection_string)
        else:
            raise ValueError("–£–∫–∞–∂–∏—Ç–µ use_managed_identity=True –∏–ª–∏ connection_string")

        logger.info(f"üîó Azure Blob initialized: {storage_account_name}/{container_name}")

    def download_parquet(self, force_reload: bool = False) -> pd.DataFrame:
        """
        –°–∫–∞—á–∏–≤–∞–µ—Ç Parquet —Ñ–∞–π–ª –∏–∑ Azure Storage

        Args:
            force_reload: –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª

        Returns:
            DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏ —Ç–æ–≤–∞—Ä–æ–≤
        """
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω—É–∂–Ω–æ –ª–∏ –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∂–∞—Ç—å
        if not force_reload and self.df is not None:
            # –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –º–µ–Ω—å—à–µ 10 –º–∏–Ω—É—Ç –Ω–∞–∑–∞–¥ - –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫—ç—à
            if self.last_loaded and (datetime.now() - self.last_loaded).seconds < 600:
                logger.info("üì¶ Using in-memory DataFrame cache")
                return self.df

        try:
            logger.info(f"üì• Downloading Parquet from Azure: {self.blob_path}")

            # –ü–æ–ª—É—á–∞–µ–º blob client
            blob_client = self.blob_service_client.get_blob_client(
                container=self.container_name,
                blob=self.blob_path
            )

            # –°–∫–∞—á–∏–≤–∞–µ–º –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            with open(self.local_cache_path, "wb") as download_file:
                download_stream = blob_client.download_blob()
                download_file.write(download_stream.readall())

            # –ß–∏—Ç–∞–µ–º Parquet –≤ DataFrame
            self.df = pd.read_parquet(self.local_cache_path)
            self.last_loaded = datetime.now()

            logger.info(f"‚úÖ Loaded {len(self.df)} products from Parquet")
            logger.info(f"üìä Columns: {list(self.df.columns)}")

            return self.df

        except Exception as e:
            logger.error(f"‚ùå Failed to download Parquet: {e}")
            # –ï—Å–ª–∏ –µ—Å—Ç—å —Å—Ç–∞—Ä—ã–π –ª–æ–∫–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª - –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ
            if self.local_cache_path.exists():
                logger.warning("‚ö†Ô∏è Using stale local cache")
                self.df = pd.read_parquet(self.local_cache_path)
                return self.df
            raise

    def get_dataframe(self) -> pd.DataFrame:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∞–∫—Ç—É–∞–ª—å–Ω—ã–π DataFrame"""
        if self.df is None:
            return self.download_parquet()
        return self.df


class DWHProductSearch:
    """–ö–ª–∞—Å—Å –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ç–æ–≤–∞—Ä–æ–≤ –≤ Parquet –¥–∞–Ω–Ω—ã—Ö –∏–∑ ADF"""

    def __init__(
            self,
            storage_account_name: str,
            container_name: str,
            blob_path: str,
            use_managed_identity: bool = True,
            connection_string: Optional[str] = None,
            redis_client: Optional[redis.Redis] = None
    ):
        self.loader = AzureParquetLoader(
            storage_account_name=storage_account_name,
            container_name=container_name,
            blob_path=blob_path,
            use_managed_identity=use_managed_identity,
            connection_string=connection_string
        )
        self.cache = DWHCache(redis_client) if redis_client else None

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏
        try:
            self.loader.download_parquet()
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Initial load failed: {e}. Will retry on first search.")

    def reload_data(self):
        """–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ Azure"""
        logger.info("üîÑ Force reloading data from Azure...")
        self.loader.download_parquet(force_reload=True)

    def search_products(
            self,
            query: Optional[str] = None,
            product_id: Optional[int] = None,
            gtin: Optional[str] = None,
            only_in_stock: bool = True,
            min_price: Optional[float] = None,
            max_price: Optional[float] = None
    ) -> List[Dict]:
        """
        –ü–æ–∏—Å–∫ —Ç–æ–≤–∞—Ä–æ–≤ –≤ DataFrame —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π

        Args:
            query: —Ç–µ–∫—Å—Ç –¥–ª—è –ø–æ–∏—Å–∫–∞ –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏ —Ç–æ–≤–∞—Ä–∞
            product_id: –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π ID —Ç–æ–≤–∞—Ä–∞
            gtin: —à—Ç—Ä–∏—Ö-–∫–æ–¥ —Ç–æ–≤–∞—Ä–∞
            only_in_stock: —Ç–æ–ª—å–∫–æ —Ç–æ–≤–∞—Ä—ã –≤ –Ω–∞–ª–∏—á–∏–∏
            min_price: –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Ü–µ–Ω–∞
            max_price: –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Ü–µ–Ω–∞
            top_n: –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

        Returns:
            –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Ç–æ–≤–∞—Ä–∞—Ö
        """
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
        if self.cache and query:
            filters = {
                'only_in_stock': only_in_stock,
                'min_price': min_price,
                'max_price': max_price,
            }
            cached_results = self.cache.get(query, filters)
            if cached_results:
                return cached_results

        try:
            # –ü–æ–ª—É—á–∞–µ–º DataFrame
            df = self.loader.get_dataframe()

            if df is None or df.empty:
                logger.warning("‚ö†Ô∏è DataFrame is empty")
                return []

            # –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
            filtered_df = df.copy()

            # –§–∏–ª—å—Ç—Ä –ø–æ ID —Ç–æ–≤–∞—Ä–∞
            if product_id is not None:
                filtered_df = filtered_df[filtered_df['MpProductID'] == product_id]

            # –§–∏–ª—å—Ç—Ä –ø–æ GTIN
            if gtin is not None:
                # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º —á—Ç–æ –µ—Å—Ç—å –∫–æ–ª–æ–Ω–∫–∞ Gtin
                if 'Gtin' in filtered_df.columns:
                    filtered_df = filtered_df[filtered_df['Gtin'] == gtin]

            # –§–∏–ª—å—Ç—Ä –ø–æ –Ω–∞–ª–∏—á–∏—é
            if only_in_stock:
                filtered_df = filtered_df[filtered_df['Qty'] > 0]

            # –§–∏–ª—å—Ç—Ä –ø–æ —Ü–µ–Ω–µ
            if min_price is not None:
                filtered_df = filtered_df[filtered_df['RetailPrice'] >= min_price]

            if max_price is not None:
                filtered_df = filtered_df[filtered_df['RetailPrice'] <= max_price]

            # –ü–æ–∏—Å–∫ –ø–æ —Ç–µ–∫—Å—Ç—É –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏
            if query is not None and query.strip():
                query_lower = query.lower()

                # –£–õ–£–ß–®–ï–ù–ù–´–ô –ü–û–ò–°–ö: –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞
                # –£–±–∏—Ä–∞–µ–º —Å—Ç–æ–ø-—Å–ª–æ–≤–∞ –∏ –≤–æ–ø—Ä–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏
                stop_words = [
                    '–∫–∞–∫–æ–≤–∞', '–∫–∞–∫–∞—è', '–∫–∞–∫–æ–π', '–∫–∞–∫–∏–µ', '—Å–∫–æ–ª—å–∫–æ', '—Å—Ç–æ–∏—Ç', '—Å—Ç–æ—è—Ç',
                    '—Ü–µ–Ω–∞', 'qiym…ôt', 'price', 'cost', '–≤', '–Ω–∞', '–∏–∑', '–¥–ª—è',
                    '–∫–∞—Ç–∞–ª–æ–≥', '–∫–∞—Ç–∞–ª–æ–≥–µ', 'catalog', '–µ—Å—Ç—å', '–ª–∏', 'var', 'mi',
                    'ne√ß…ô', 'n…ô', 'q…ôd…ôr', 'q…ôd…ôrdir', 'how', 'much', 'what', 'is'
                ]

                # –†–∞–∑–±–∏–≤–∞–µ–º –∑–∞–ø—Ä–æ—Å –Ω–∞ —Å–ª–æ–≤–∞ –∏ —É–±–∏—Ä–∞–µ–º —Å—Ç–æ–ø-—Å–ª–æ–≤–∞
                query_words = [
                    word for word in query_lower.split()
                    if word not in stop_words and len(word) > 2
                ]

                # –ï—Å–ª–∏ –æ—Å—Ç–∞–ª–∏—Å—å –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ - –∏—â–µ–º –∏—Ö
                if query_words:
                    # –°–æ–∑–¥–∞–µ–º –º–∞—Å–∫—É: —Ç–æ–≤–∞—Ä –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ –∫–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ
                    mask = pd.Series([False] * len(filtered_df))

                    for word in query_words:
                        # –ò—â–µ–º –∫–∞–∂–¥–æ–µ —Å–ª–æ–≤–æ –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏
                        word_mask = filtered_df['Name'].str.lower().str.contains(word, na=False, regex=False)
                        mask = mask | word_mask

                        # –¢–∞–∫–∂–µ –∏—â–µ–º –≤ Description –µ—Å–ª–∏ –µ—Å—Ç—å
                        if 'Description' in filtered_df.columns:
                            desc_mask = filtered_df['Description'].str.lower().str.contains(word, na=False, regex=False)
                            mask = mask | desc_mask

                    filtered_df = filtered_df[mask]
                else:
                    # –ï—Å–ª–∏ –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –Ω–µ –æ—Å—Ç–∞–ª–æ—Å—å —Å–ª–æ–≤ - –∏—â–µ–º –ø–æ –∏—Å—Ö–æ–¥–Ω–æ–º—É –∑–∞–ø—Ä–æ—Å—É
                    mask = filtered_df['Name'].str.lower().str.contains(query_lower, na=False)

                    if 'Description' in filtered_df.columns:
                        mask |= filtered_df['Description'].str.lower().str.contains(query_lower, na=False)

                    filtered_df = filtered_df[mask]

            # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞: —Å–Ω–∞—á–∞–ª–∞ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É (–±–æ–ª—å—à–µ = –ª—É—á—à–µ), –ø–æ—Ç–æ–º –ø–æ —Ü–µ–Ω–µ (–º–µ–Ω—å—à–µ = –ª—É—á—à–µ)
            filtered_df = filtered_df.sort_values(
                by=['Qty', 'RetailPrice'],
                ascending=[False, True]
            )

            # FALLBACK: –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –ø–æ–ø—Ä–æ–±—É–µ–º –±–æ–ª–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫
            if len(filtered_df) == 0 and query is not None:
                logger.info(f"‚ö†Ô∏è No results with keyword search, trying fallback...")

                # –ü–æ–ø—Ä–æ–±—É–µ–º –∏—Å–∫–∞—Ç—å –ø–æ —á–∞—Å—Ç–∏—á–Ω—ã–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è–º (–ø–µ—Ä–≤—ã–µ 3 –±—É–∫–≤—ã –∫–∞–∂–¥–æ–≥–æ —Å–ª–æ–≤–∞)
                df_original = self.loader.get_dataframe()

                # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ç–æ–ª—å–∫–æ —Ñ–∏–ª—å—Ç—Ä—ã (–±–µ–∑ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –ø–æ–∏—Å–∫–∞)
                if only_in_stock:
                    df_original = df_original[df_original['Qty'] > 0]
                if min_price is not None:
                    df_original = df_original[df_original['RetailPrice'] >= min_price]
                if max_price is not None:
                    df_original = df_original[df_original['RetailPrice'] <= max_price]

                # –ò—â–µ–º –ø–æ –ø–µ—Ä–≤—ã–º –±—É–∫–≤–∞–º (–¥–ª—è –æ–ø–µ—á–∞—Ç–æ–∫ —Ç–∏–ø–∞ "–∞–π—Ñ–æ–Ω" –≤–º–µ—Å—Ç–æ "iPhone")
                query_words = query.lower().split()
                mask = pd.Series([False] * len(df_original))

                for word in query_words:
                    if len(word) >= 3:
                        # –ò—â–µ–º —Å–ª–æ–≤–∞ –Ω–∞—á–∏–Ω–∞—é—â–∏–µ—Å—è —Å —ç—Ç–∏—Ö –±—É–∫–≤
                        pattern = word[:3]
                        word_mask = df_original['Name'].str.lower().str.contains(pattern, na=False, regex=False)
                        mask = mask | word_mask

                if mask.any():
                    filtered_df = df_original[mask].sort_values(
                        by=['Qty', 'RetailPrice'],
                        ascending=[False, True]
                    )
                    logger.info(f"‚úÖ Fallback found {len(filtered_df)} results")

            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π
            results = filtered_df.to_dict('records')

            logger.info(f"üîç Search for '{query}': found {len(results)} products")

            # –ö—ç—à–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            if self.cache and query:
                self.cache.set(query, filters, results)

            return results

        except Exception as e:
            logger.error(f"‚ùå Search error: {e}")
            return []

    def get_product_by_id(self, product_id: int) -> Optional[Dict]:
        """–ü–æ–ª—É—á–∏—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Ç–æ–≤–∞—Ä –ø–æ ID"""
        results = self.search_products(product_id=product_id, only_in_stock=False)
        return results[0] if results else None

    def format_products_for_llm(self, products: List[Dict], language: str = 'ru', max_display: int = None) -> str:
        """
        –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –¥–ª—è –ø–µ—Ä–µ–¥–∞—á–∏ –≤ LLM

        Args:
            products: —Å–ø–∏—Å–æ–∫ —Ç–æ–≤–∞—Ä–æ–≤
            language: —è–∑—ã–∫ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (ru, az, en)
            max_display: –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–≤–∞—Ä–æ–≤ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è (None = –≤—Å–µ)

        Returns:
            –û—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å—Ç—Ä–æ–∫–∞ —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Ç–æ–≤–∞—Ä–∞—Ö
        """
        if not products:
            return ""

        # –ó–∞–≥–æ–ª–æ–≤–∫–∏ –∏ —à–∞–±–ª–æ–Ω—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —è–∑—ã–∫–æ–≤
        templates = {
            'ru': {
                'header': "üì¶ –ù–∞–π–¥–µ–Ω–Ω—ã–µ —Ç–æ–≤–∞—Ä—ã –∏–∑ –∫–∞—Ç–∞–ª–æ–≥–∞:\n\n",
                'template': """‚Ä¢ {Name}
  üí∞ –¶–µ–Ω–∞: {RetailPrice} AZN
  üè™ –ü—Ä–æ–¥–∞–≤–µ—Ü: {MerchantMarketingName}
  {installment}
  ID: {MpProductID}
""",
                'installment_yes': "üí≥ –†–∞—Å—Å—Ä–æ—á–∫–∞: –¥–æ {months} –º–µ—Å—è—Ü–µ–≤",
                'installment_no': "üí≥ –†–∞—Å—Å—Ä–æ—á–∫–∞: –Ω–µ –¥–æ—Å—Ç—É–ø–Ω–∞",
                'more': "...–∏ –µ—â—ë {count} —Ç–æ–≤–∞—Ä–æ–≤\n"
            },
            'az': {
                'header': "üì¶ Kataloqdan tapƒ±lan m…ôhsullar:\n\n",
                'template': """‚Ä¢ {Name}
  üí∞ Qiym…ôt: {RetailPrice} AZN
  üè™ Satƒ±cƒ±: {MerchantMarketingName}
  {installment}
  ID: {MpProductID}
""",
                'installment_yes': "üí≥ Taksit: {months} aya q…ôd…ôr",
                'installment_no': "üí≥ Taksit: m√∂vcud deyil",
                'more': "...v…ô daha {count} m…ôhsul\n"
            },
            'en': {
                'header': "üì¶ Products found in catalog:\n\n",
                'template': """‚Ä¢ {Name}
  üí∞ Price: {RetailPrice} AZN
  üè™ Seller: {MerchantMarketingName}
  {installment}
  ID: {MpProductID}
""",
                'installment_yes': "üí≥ Installment: up to {months} months",
                'installment_no': "üí≥ Installment: not available",
                'more': "...and {count} more products\n"
            }
        }

        # –í—ã–±–∏—Ä–∞–µ–º —à–∞–±–ª–æ–Ω –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ä—É—Å—Å–∫–∏–π –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        lang_template = templates.get(language, templates['ru'])

        formatted = lang_template['header']

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–∫–æ–ª—å–∫–æ —Ç–æ–≤–∞—Ä–æ–≤ –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å
        if max_display is None:
            # –£–º–Ω–∞—è –ª–æ–≥–∏–∫–∞: –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –±–æ–ª—å—à–µ –µ—Å–ª–∏ –Ω–∞—à–ª–æ—Å—å –º–∞–ª–æ
            if len(products) <= 3:
                display_count = len(products)
            elif len(products) <= 10:
                display_count = len(products)  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –≤—Å–µ –¥–æ 10
            else:
                display_count = 10  # –ú–∞–∫—Å–∏–º—É–º 10
        else:
            display_count = min(max_display, len(products))

        for product in products[:display_count]:
            # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ä–∞—Å—Å—Ä–æ—á–∫–µ
            installment = (
                lang_template['installment_yes'].format(
                    months=product.get('MaxInstallmentMonths', 0)
                )
                if product.get('InstallmentEnabled')
                else lang_template['installment_no']
            )

            # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–≤–∞—Ä
            formatted += lang_template['template'].format(
                Name=product.get('Name', 'N/A'),
                RetailPrice=product.get('RetailPrice', 'N/A'),
                MerchantMarketingName=product.get('MerchantMarketingName', 'N/A'),
                installment=installment,
                MpProductID=product.get('MpProductID', 'N/A')
            )
            formatted += "\n"

        # –ï—Å–ª–∏ —Ç–æ–≤–∞—Ä–æ–≤ –±–æ–ª—å—à–µ —á–µ–º –ø–æ–∫–∞–∑–∞–ª–∏, —É–∫–∞–∑—ã–≤–∞–µ–º —Å–∫–æ–ª—å–∫–æ –µ—â—ë
        if len(products) > display_count:
            formatted += lang_template['more'].format(count=len(products) - display_count)

        return formatted

    def search_by_brand(self, brand: str, **kwargs) -> List[Dict]:
        """–ü–æ–∏—Å–∫ —Ç–æ–≤–∞—Ä–æ–≤ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –±—Ä–µ–Ω–¥–∞"""
        return self.search_products(query=brand, **kwargs)

    def search_in_price_range(
            self,
            min_price: float,
            max_price: float,
            category_query: Optional[str] = None,
            **kwargs
    ) -> List[Dict]:
        """–ü–æ–∏—Å–∫ —Ç–æ–≤–∞—Ä–æ–≤ –≤ —Ü–µ–Ω–æ–≤–æ–º –¥–∏–∞–ø–∞–∑–æ–Ω–µ"""
        return self.search_products(
            query=category_query,
            min_price=min_price,
            max_price=max_price,
            **kwargs
        )

    def debug_search(self, query: str) -> Dict:
        """
        –û—Ç–ª–∞–¥–æ—á–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ –ø–æ–∏—Å–∫–∞
        """
        df = self.loader.get_dataframe()

        if df is None or df.empty:
            return {"error": "DataFrame is empty"}

        query_lower = query.lower()

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –µ—Å—Ç—å –≤ –±–∞–∑–µ
        sample_names = df['Name'].head(10).tolist() if 'Name' in df.columns else []

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
        stop_words = [
            '–∫–∞–∫–æ–≤–∞', '–∫–∞–∫–∞—è', '–∫–∞–∫–æ–π', '–∫–∞–∫–∏–µ', '—Å–∫–æ–ª—å–∫–æ', '—Å—Ç–æ–∏—Ç', '—Å—Ç–æ—è—Ç',
            '—Ü–µ–Ω–∞', 'qiym…ôt', 'price', 'cost', '–≤', '–Ω–∞', '–∏–∑', '–¥–ª—è',
            '–∫–∞—Ç–∞–ª–æ–≥', '–∫–∞—Ç–∞–ª–æ–≥–µ', 'catalog', '–µ—Å—Ç—å', '–ª–∏', 'var', 'mi'
        ]
        query_words = [
            word for word in query_lower.split()
            if word not in stop_words and len(word) > 2
        ]

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–∫–æ–ª—å–∫–æ —Ç–æ–≤–∞—Ä–æ–≤ —Å–æ–¥–µ—Ä–∂–∞—Ç –∫–∞–∂–¥–æ–µ —Å–ª–æ–≤–æ
        word_matches = {}
        for word in query_words:
            count = df['Name'].str.lower().str.contains(word, na=False).sum()
            word_matches[word] = count

        return {
            "query": query,
            "extracted_keywords": query_words,
            "word_matches": word_matches,
            "total_products": len(df),
            "sample_names": sample_names
        }

    def get_statistics(self) -> Dict:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –¥–∞–Ω–Ω—ã–º"""
        try:
            df = self.loader.get_dataframe()
            if df is None or df.empty:
                return {}

            return {
                'total_products': len(df),
                'in_stock_products': len(df[df['Qty'] > 0]),
                'avg_price': float(df['RetailPrice'].mean()),
                'min_price': float(df['RetailPrice'].min()),
                'max_price': float(df['RetailPrice'].max()),
                'last_updated': self.loader.last_loaded.isoformat() if self.loader.last_loaded else None
            }
        except Exception as e:
            logger.error(f"Error getting statistics: {e}")
            return {}


# ==================== –ì–õ–û–ë–ê–õ–¨–ù–´–ô –≠–ö–ó–ï–ú–ü–õ–Ø–† ====================

# –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
import os
from dotenv import load_dotenv

load_dotenv()

# Azure Storage –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
STORAGE_ACCOUNT_NAME = os.getenv('AZURE_STORAGE_ACCOUNT_NAME', 'your_storage_account')
CONTAINER_NAME = os.getenv('AZURE_CONTAINER_NAME', 'birmarket-data')
BLOB_PATH = os.getenv('AZURE_BLOB_PATH', 'dwh/products/latest.parquet')

# –î–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–π —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å connection string
STORAGE_CONNECTION_STRING = os.getenv('AZURE_STORAGE_CONNECTION_STRING')

# –ò—Å–ø–æ–ª—å–∑—É–µ–º Managed Identity –≤ production, connection string –≤ dev
USE_MANAGED_IDENTITY = os.getenv('USE_MANAGED_IDENTITY', 'true').lower() == 'true'

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Redis –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
try:
    redis_client = redis.Redis(
        host=os.getenv('REDIS_HOST', 'localhost'),
        port=int(os.getenv('REDIS_PORT', 6379)),
        db=int(os.getenv('REDIS_DB', 0)),
        decode_responses=True
    )
    redis_client.ping()
    logger.info("‚úÖ Redis connected for caching")
except Exception as e:
    logger.warning(f"‚ö†Ô∏è Redis not available: {e}")
    redis_client = None

# –°–æ–∑–¥–∞–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä
dwh_search = DWHProductSearch(
    storage_account_name=STORAGE_ACCOUNT_NAME,
    container_name=CONTAINER_NAME,
    blob_path=BLOB_PATH,
    use_managed_identity=USE_MANAGED_IDENTITY,
    connection_string=STORAGE_CONNECTION_STRING if not USE_MANAGED_IDENTITY else None,
    redis_client=redis_client
)

__all__ = ['dwh_search', 'DWHProductSearch']